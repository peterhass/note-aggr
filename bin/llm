#!/usr/bin/env bash
set -euo pipefail

: "${LLM_MODEL:=gpt-4}"
: "${LLM_BASE_URL:=http://localhost:11434/v1}" # Ollama default
: "${LLM_API_KEY:=}"                           

prompt="$(cat -)"
#echo "$prompt" >&2

auth_args=()
if [[ -n "$LLM_API_KEY" ]]; then
  auth_args=( "Authorization:Bearer $LLM_API_KEY" )
fi

jq -n \
  --arg model "$LLM_MODEL" \
  --arg prompt "$prompt" \
  '{
    model: $model,
    temperature: 0.7,
    reasoning_effort: "high",
    messages: [
      {role: "system", content: "You are a highly intelligent assistant capable of deep reasoning and critical thinking."},
      {role: "user", content: $prompt}
    ]
  }' \
  | http --check-status \
    POST "$LLM_BASE_URL/chat/completions" \
    Content-Type:application/json \
    "${auth_args[@]}" \
  | jq -r '.choices[0].message.content'
